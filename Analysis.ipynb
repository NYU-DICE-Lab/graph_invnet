{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis code for Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from models import wgan\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_noise():\n",
    "    noise = torch.randn(BATCH_SIZE, 128)\n",
    "    noise = noise.cpu()\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training, we used the normalized value of the pixel, and pList and rList converts the unit of pixel to normalized value to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pConverter(x):\n",
    "    \"\"\"\n",
    "    x: an integer from 30 to 96.\n",
    "    \"\"\"\n",
    "    if type(x) is not int:\n",
    "        raise Exception(\"Should be integer\")\n",
    "    if x > 96 or x < 30:\n",
    "        raise Exeption(\"Pixel should be in 29<x<97.\")\n",
    "        \n",
    "    return x/128\n",
    "\n",
    "def rConverter(x):\n",
    "    \"\"\"\n",
    "    x: an integer from 14 to 32.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(x) is not int:\n",
    "        raise Exception(\"Should be integer\")\n",
    "    if x > 32 or x < 14:\n",
    "        raise Exeption(\"Pixel should be in 13<x<33.\")\n",
    "        \n",
    "    return np.pi*x*x/128/128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating circles with the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The toy dataset has three channels with dimension 128 for width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "CHANNEL = 3\n",
    "DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to the generator file. *.pt.\n",
    "aG = torch.load('./output/test/generator.pt', map_location='cpu')\n",
    "aG.eval()\n",
    "fixed_noise = gen_rand_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of tuning parameter is following: $c_{1, x}, c_{2, x},c_{1, y},c_{2, y},r_{1},r_{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAESElEQVR4nO3dTU4iUQBGUezoimD/K4AVOaAHBkMQ/MEqua/qnGF3GsvE6/cKkX46Ho8boOffoy8AuE6cECVOiBInRIkTop4/+8vD4eCpXJjZdrt9uvbnlhOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocULUp/+R0RJsD7vJHuuw3U/2WPAVywlRi1rOKVfyO49vSZnT8HHOHeRXH1ugzMWxFqKGXc5HLua503VYUKZmOSFqqOWsrOU1FpSpWc6Jlb+BMBZxQtQQx1prxBpZTohKL+eoi+nJIaZgOSFKnBCVjXPUI+257WG3iM+Dx8jGCWsnTogSJ0TlfpTiHg3eWE6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVG5F74vifcQ4jcsJ0SJE6LECVHuOWfgXpMpWE6IEidE5eI8bPdDHwtHvnZacnECbzwhNBGLydQsJ0Rl47RErF36WHsKtPpG076BMKfscsLapZfzpLagFpO/YDkhaqg4H71Yo79AgrEMcaw9dyuOuY68YuRRhlpOWJPhlvMWC8fSWE6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtTzoy+A9XjZ7e7+t6/7/YRXMgbLCVGWk1n8ZiW/83hrWFLLCVGWk0lNvZjf+ThLXVFx8mt/FeRXH39pkTrWQpTl5G6PXsxLS1tQywlR4uQutdU8V762n3Cs5UdG+cJfwhHXckKU5eRbRlnMSyMvqOWEKHFClDghyj0nnxr1XvPSiPeelpOblhLmqMQJUeJkVUY6DYgTojwhxAcjrcuSiZN3omxxrIUocbI6L7vdEKcEcUKUOCFKnGw2G08GFYkTosQJUeKEKC9CWDn3ml2WE6LECVHihChxQpQ4IUqcEOVHKazOKO/AZzkhSpwQJU6IEidEiROixLlyr/v9MM9eTmGkz1WcECVOiBInRImTzWYz1r3YWogTory2llUY8WQgTt6dvoCX9L5CI0Z54lgLUeKEKHFClHtOPljCvefI95onlpObRv0CH/W6L4kTohxr+dTlChWPuktZykuWE6LEyY/Ufv+zdC1TEydEuefkLtcWa8770SUv5C3iZDLnAd0b6hojvMWxFqIsJ7OwgL9nOSFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IerpeDw++hqAKywnRIkTosQJUeKEKHFClDgh6j97lqdx5EL4bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lv = torch.FloatTensor([pConverter(30), pConverter(90), pConverter(30), pConverter(90),\n",
    "                        rConverter(15), rConverter(20)]).repeat(BATCH_SIZE, 1)\n",
    "gen_images = aG(gen_rand_noise(), lv).view(BATCH_SIZE, CHANNEL, DIM, DIM)\n",
    "image = gen_images.detach().numpy()\n",
    "image = np.argmax(image, axis=1)\n",
    "plt.imshow(image[0], cmap='nipy_spectral')\n",
    "plt.axis('off')\n",
    "plt.clim(-6, 1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
